For local test - using 3-forest database, no schemas, REST API app server on port 8004.

With MLCP config:

mlcp.sh IMPORT -host localhost -port 8004 -username admin -password admin -input_file_path "data/ecs500k.csv"
-input_file_type "delimited_text" -thread_count 16 -output_permissions "rest-reader,read,rest-writer,update" -output_collections "ecs" -output_uri_prefix "/ecs/" -output_uri_suffix ".json" -document_type json

Running locally, took 2m3s to load 500k docs.

With Spark - 97s.
One functional difference - Spark csv does not trim each cell, so a leading space in each column in the test CSV file
is retained.



mlcp.sh IMPORT -host 3.95.147.121 -port 8005 -username admin -password "i-0883db2d2a0296b86" -input_file_path "/Users/rrudin/workspace/hok-mlcp/data/ecs200k.csv" -input_file_type "delimited_text" -thread_count 16 -output_permissions "rest-reader,read,rest-writer,update" -output_collections "ecs" -output_uri_prefix "/ecs/" -output_uri_suffix ".xml"

./build/install/new-tool-cli/bin/new-tool-cli import --path "/Users/rrudin/workspace/hok-mlcp/data/ecs200k.csv" --port 8004 --host 3.95.147.121 --username admin --password "i-0883db2d2a0296b86" --partitions 16

Against single-node cluster on AWS EC2 instance - r4.8xlarge:

Spark
4 partitions = 65.8s
16 partitions = 47s
32 partitions = 45.3

MLCP
4 threads =
16 threads = 337s
32 threads =

200k docs instead of 500k

Spark
16 partitions = 22.9s

MLCP
16 threads = 152
32 threads =



Against the internal 3-node cluster at 172.18.17.44

mlcp.sh IMPORT -host 172.18.17.44,172.18.17.45,172.18.17.46 -port 8005 -username admin -password admin -input_file_path ecs200k.csv -input_file_type "delimited_text" -thread_count 16 -output_permissions "rest-reader,read,rest-writer,update" -output_collections "ecs" -output_uri_prefix "/ecs/" -output_uri_suffix ".xml"

./build/install/new-tool-cli/bin/new-tool-cli import --path ecs200k.csv --port 8004 --host 172.18.17.44 --username admin --password admin --partitions 4

Spark
16 partitions = 47.1s
4 partitions = 74.3s

MLCP

